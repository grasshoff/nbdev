{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev_template.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Metadata and Upload to Zenodo\n",
    "\n",
    "> This notebook will check the metadata according to certain norms and if they are correct, it will upload the data to Zenodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile(f):\n",
    "    ending = f.suffix.replace('.', '')\n",
    "    path = str(f)\n",
    "    if ending == 'json':\n",
    "        try:\n",
    "            d = pd.read_json(path, orient = 'table')\n",
    "        except:\n",
    "            d = pd.read_json(path)\n",
    "    if ending == 'csv':\n",
    "        try:\n",
    "            d = pd.read_csv(path, delimiter = ',')\n",
    "        except:\n",
    "            try:\n",
    "                d = pd.read_csv(path, delimiter = '\\t')\n",
    "            except:\n",
    "                d = pd.read_csv(path, delimiter = ';')\n",
    "    if ending == 'yaml' or ending == 'cite':\n",
    "        with open(path) as yml:\n",
    "            d = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "    if ending == 'md':\n",
    "        with open(path, encoding=\"utf8\") as file:\n",
    "            d = file.read()\n",
    "            display(Markdown(d))\n",
    "    return d\n",
    "\n",
    "def findkeys(c):\n",
    "    ck = list(c.keys())\n",
    "    mk = list(c['Metadata'].keys())\n",
    "    prk = [list(i.keys()) for i in c['Resources']]\n",
    "    rk = [list(i.keys()) for i in c['Resources']][0]\n",
    "    ak = [list(i['Attributes'].keys()) for i in c['Resources']]\n",
    "    return ck, mk, prk, rk, ak\n",
    "\n",
    "def checkVal(c, mk, ak):\n",
    "    mke = []\n",
    "    for i in mk:\n",
    "        if c['Metadata'][i].strip() == '':\n",
    "            print('Key {} may not be empty!'.format(i))\n",
    "            mke.append(i)\n",
    "    ake = []\n",
    "    for i in ak:\n",
    "        a = []\n",
    "        for j in range(len(i)):\n",
    "            if i[j].strip() == '':\n",
    "                print('Key {} may not be empty!'.format(i[j]))\n",
    "                mke.append(i[j])\n",
    "    if not (mke or ake):\n",
    "        message = None\n",
    "        print('All metadata keys and attributes are filled, wonderful!')\n",
    "    else:\n",
    "        message = 'bad'\n",
    "    return mke, ake, message\n",
    "\n",
    "def checkkeys(pk, k):\n",
    "    ke = []\n",
    "    for i in pk:\n",
    "        if i not in k:\n",
    "            message = 'bad'\n",
    "            print('The key {} does not exist in your metadata, please add it!'.format(i))\n",
    "            ke.append(i)\n",
    "        else:\n",
    "            message = None\n",
    "    return ke, message\n",
    "\n",
    "def congrat(c1, c2, c3):\n",
    "    if not (c1 or c2 or c3):\n",
    "        message = None\n",
    "        print('Congrats, all keys are set!')\n",
    "    else:\n",
    "        message = 'bad'\n",
    "    return message\n",
    "\n",
    "def comparekeys(allfn, cf, caks, dataDFkeys):\n",
    "    if allfn != cf:\n",
    "        missf = cf - allfn\n",
    "        addedf = allfn - cf\n",
    "        missk = []\n",
    "        addedk = []\n",
    "        messages = []\n",
    "        print('You did not commented the file {} in your cite! Please to so!'.format(addedf))\n",
    "        print('The file {} is not in the directory, please remove it from the cite!'.format(missf))\n",
    "        messages.append('bad')\n",
    "    else:\n",
    "        missf = None\n",
    "        addedf = None\n",
    "        missk = []\n",
    "        addedk = []\n",
    "        allfn = list(allfn)\n",
    "        messages = []\n",
    "        for i in range(len(allfn)):\n",
    "            print(allfn[i])\n",
    "            print(i)\n",
    "            if caks[i] != dataDFkeys[i]:\n",
    "                misski = dataDFkeys[i] - caks[i]\n",
    "                addedki = caks[i] - dataDFkeys[i]\n",
    "                messages.append('bad')\n",
    "                print('You did not commented the key {} in your cite! Please to so!'.format(misski))\n",
    "                print('The key {} is not your data, please remove it from the cite!'.format(addedki))\n",
    "                missk.append(misski)\n",
    "                addedk.append(addedki)\n",
    "        print(missk)\n",
    "    if len(messages) == 0:\n",
    "        message = None\n",
    "    else:\n",
    "        message = 'bad'\n",
    "                \n",
    "    return missf, addedf, missk, addedk, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEmptyUpload(sandbox, ACCESS_TOKEN):\n",
    "    \n",
    "    # Create empty upload first to get the bucket_url\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    params = {'access_token': ACCESS_TOKEN}\n",
    "    if sandbox:\n",
    "        r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions', params=params, json={}, headers=headers)\n",
    "    else:\n",
    "        r = requests.post('https://zenodo.org/api/deposit/depositions', params=params, json={}, headers=headers)\n",
    "    print(r.status_code)\n",
    "    bucket_url = r.json()[\"links\"][\"bucket\"]\n",
    "    return bucket_url, params\n",
    "\n",
    "def uploadOneFile(bucket_url, params, filepath):\n",
    "\n",
    "    # Give file\n",
    "    p = Path(filepath)\n",
    "    file = p.open(\"rb\")\n",
    "    filename = p.name\n",
    "    \n",
    "    # Upload file\n",
    "    r = requests.put(\"%s/%s\" % (bucket_url, filename), data=file, params=params)\n",
    "    \n",
    "    return r.json()\n",
    "    \n",
    "def uploadDirectory(bucket_url, params, dirpath):\n",
    "\n",
    "    # Find all files in directory\n",
    "    \n",
    "    p = Path(dirpath)\n",
    "    allfil = list(p.glob('*'))\n",
    "    allfiles = [i.open(\"rb\") for i in allfil]\n",
    "    allfilenames = [i.name for i in allfil]\n",
    "    \n",
    "    # Upload files\n",
    "    rs = []\n",
    "    for i in range(len(allfiles)):\n",
    "        r = requests.put(\"%s/%s\" % (bucket_url, allfilenames[i]), data=allfiles[i], params=params)\n",
    "        rs.append(r.json())\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## publprofil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/publprofil.yaml') as yml:\n",
    "    pp = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "pp = pp['ResearchObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "pck, pmk, pprk, prk, pak = findkeys(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./data/ModernLocationsIberia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfile = list(p.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfn = set([i.name for i in allfile if not i.suffix == '.cite' and not i.suffix == '.md'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(sorted([i for i in allfile if i.suffix == '.cite']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = openfile(c)['ResearchObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "cck, cmk, cprk, crk, cak = findkeys(cite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "caks = [set(i) for i in cak]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cf = set([i['File'.lower()] for i in cite['Resources']])\n",
    "except:\n",
    "    cf = set([i['File'] for i in cite['Resources']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(sorted([i for i in allfile if not i.suffix == '.cite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDFkeys = [set(openfile(f).keys()) for f in d if f.suffix == '.json' or f.suffix == '.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Metadata keys & Attributes are not empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All metadata keys and attributes are filled, wonderful!\n"
     ]
    }
   ],
   "source": [
    "cmke, cake, message1 = checkVal(cite, pmk, pak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check existence of all keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = checkkeys(pck, cck)\n",
    "c2 = checkkeys(pmk, cmk)\n",
    "c3 = []\n",
    "for i in cprk:\n",
    "    c3.append(checkkeys(prk, i))\n",
    "message2 = congrat(c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If data is identical to cite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did not commented the file {'ModernLocationsIberia.csv'} in your cite! Please to so!\n",
      "The file {'ModernLocationsIberia.xlsx'} is not in the directory, please remove it from the cite!\n"
     ]
    }
   ],
   "source": [
    "missf, addedf, missk, addedk, message3 = comparekeys(allfn, cf, caks, dataDFkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload on Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is any error in the cite, the process is terminated; otherwise one proceed with upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if (message1 or message2 or message3):\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sandbox (for testing purposes) = sandbox ACCESS_TOKEN from https://sandbox.zenodo.org/account/settings/applications/tokens/new/\n",
    "\n",
    "real data (for real upload) = ACCESS_TOKEN from https://zenodo.org/account/settings/applications/tokens/new/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Register for a Zenodo sandbox account if you don't already have one.\n",
    "    Go to https://sandbox.zenodo.org/account/settings/applications/tokens/new/.\n",
    "    Select the OAuth scopes you need (for the quick start tutorial you need deposit:write and deposit:actions).\n",
    "    Please insert your just generated token for ... below.\n",
    "'''\n",
    "\n",
    "ACCESS_TOKEN = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLY CHANGE SANDBOX TO FALSE IF YOU KNOW WHAT YOU ARE DOING, THIS WILL BE A REAL UPLOAD THEN! If you want to test something always use sandbox!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "bucket_url, params = makeEmptyUpload(True, ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a number lower than 400 everything is fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mimetype': 'application/octet-stream',\n",
       "  'updated': '2020-12-16T15:43:26.187743+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsDocu.md',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsDocu.md?versionId=ca0bbff7-07de-498a-b61d-05ba15193f4f',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsDocu.md?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T15:43:26.182095+00:00',\n",
       "  'checksum': 'md5:a5351624ad3e1a780108ed6d88b510fe',\n",
       "  'version_id': 'ca0bbff7-07de-498a-b61d-05ba15193f4f',\n",
       "  'delete_marker': False,\n",
       "  'key': 'ModernLocationsDocu.md',\n",
       "  'size': 734},\n",
       " {'mimetype': 'application/octet-stream',\n",
       "  'updated': '2020-12-16T15:43:26.700750+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.cite',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.cite?versionId=d2aed9ae-98a6-487d-afe5-3a6fcfa603d7',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.cite?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T15:43:26.696147+00:00',\n",
       "  'checksum': 'md5:d0fb478e1e5bb6d886217dd16396eef3',\n",
       "  'version_id': 'd2aed9ae-98a6-487d-afe5-3a6fcfa603d7',\n",
       "  'delete_marker': False,\n",
       "  'key': 'ModernLocationsIberia.cite',\n",
       "  'size': 1171},\n",
       " {'mimetype': 'text/csv',\n",
       "  'updated': '2020-12-16T15:43:27.272359+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.csv',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.csv?versionId=ccaa70b9-c22a-4f01-bdae-a848011e94aa',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/a4eef343-e449-400c-84e2-f1c8e9b29c39/ModernLocationsIberia.csv?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T15:43:27.267774+00:00',\n",
       "  'checksum': 'md5:cfc425f53644b6e9a587e32986c3bf57',\n",
       "  'version_id': 'ccaa70b9-c22a-4f01-bdae-a848011e94aa',\n",
       "  'delete_marker': False,\n",
       "  'key': 'ModernLocationsIberia.csv',\n",
       "  'size': 22730}]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadDirectory(bucket_url, params, str(p.resolve()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
