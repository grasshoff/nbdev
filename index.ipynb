{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev_template.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Metadata and Upload to Zenodo\n",
    "\n",
    "> This notebook will check the metadata according to certain norms and if they are correct, it will upload the data to Zenodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile(f):\n",
    "    ending = str(f).split('.')[-1]\n",
    "    path = str(f)\n",
    "    if ending == 'json':\n",
    "        try:\n",
    "            d = pd.read_json(path, orient = 'table')\n",
    "        except:\n",
    "            d = pd.read_json(path)\n",
    "    if ending == 'csv':\n",
    "        try:\n",
    "            d = pd.read_csv(path, delimiter = ',')\n",
    "        except:\n",
    "            d = pd.read_csv(path, delimiter = '\\t')\n",
    "    if ending == 'yaml' or ending == 'cite':\n",
    "        with open(path) as yml:\n",
    "            d = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "    return d\n",
    "\n",
    "def findkeys(c):\n",
    "    ck = list(c.keys())\n",
    "    mk = list(c['Metadata'].keys())\n",
    "    prk = [list(i.keys()) for i in c['Resources']]\n",
    "    rk = [list(i.keys()) for i in c['Resources']][0]\n",
    "    ak = [list(i['Attributes'].keys()) for i in c['Resources']]\n",
    "    return ck, mk, prk, rk, ak\n",
    "\n",
    "def checkVal(c, mk, ak):\n",
    "    mke = []\n",
    "    for i in mk:\n",
    "        if c['Metadata'][i].strip() == '':\n",
    "            print('Key {} may not be empty!'.format(i))\n",
    "            mke.append(i)\n",
    "    ake = []\n",
    "    for i in ak:\n",
    "        a = []\n",
    "        for j in range(len(i)):\n",
    "            if i[j].strip() == '':\n",
    "                print('Key {} may not be empty!'.format(i[j]))\n",
    "                mke.append(i[j])\n",
    "    if not (mke or ake):\n",
    "        message = None\n",
    "        print('All metadata keys and attributes are filled, wonderful!')\n",
    "    else:\n",
    "        message = 'bad'\n",
    "    return mke, ake, message\n",
    "\n",
    "def checkkeys(pk, k):\n",
    "    ke = []\n",
    "    for i in pk:\n",
    "        if i not in k:\n",
    "            message = 'bad'\n",
    "            print('The key {} does not exist in your metadata, please add it!'.format(i))\n",
    "            ke.append(i)\n",
    "        else:\n",
    "            message = None\n",
    "    return ke, message\n",
    "\n",
    "def congrat(c1, c2, c3):\n",
    "    if not (c1 or c2 or c3):\n",
    "        message = None\n",
    "        print('Congrats, all keys are set!')\n",
    "    else:\n",
    "        message = 'bad'\n",
    "    return message\n",
    "\n",
    "def comparekeys(allfn, cf, caks, dataDFkeys):\n",
    "    if allfn != cf:\n",
    "        missf = cf - allfn\n",
    "        addedf = allfn - cf\n",
    "        message = 'bad'\n",
    "        print('You did not commented the file {} in your cite! Please to so!'.format(missf))\n",
    "        print('The file {} is not in the directory, please remove it from the cite!'.format(addedf))\n",
    "    else:\n",
    "        missf = None\n",
    "        addedf = None\n",
    "        missk = []\n",
    "        addedk = []\n",
    "        allfn = list(allfn)\n",
    "        messages = []\n",
    "        for i in range(len(allfn)):\n",
    "            print(allfn[i])\n",
    "            print(i)\n",
    "            if caks[i] != dataDFkeys[i]:\n",
    "                misski = dataDFkeys[i] - caks[i]\n",
    "                addedki = caks[i] - dataDFkeys[i]\n",
    "                messages.append('bad')\n",
    "                print('You did not commented the key {} in your cite! Please to so!'.format(misski))\n",
    "                print('The key {} is not your data, please remove it from the cite!'.format(addedki))\n",
    "                missk.append(misski)\n",
    "                addedk.append(addedki)\n",
    "        if len(messages) == 0:\n",
    "            message = None\n",
    "        else:\n",
    "            message = 'bad'\n",
    "                \n",
    "    return missf, addedf, missk, addedk, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEmptyUpload(sandbox, ACCESS_TOKEN):\n",
    "    \n",
    "    # Create empty upload first to get the bucket_url\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    params = {'access_token': ACCESS_TOKEN}\n",
    "    if sandbox:\n",
    "        r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions', params=params, json={}, headers=headers)\n",
    "    else:\n",
    "        r = requests.post('https://zenodo.org/api/deposit/depositions', params=params, json={}, headers=headers)\n",
    "    print(r.status_code)\n",
    "    bucket_url = r.json()[\"links\"][\"bucket\"]\n",
    "    return bucket_url, params\n",
    "\n",
    "def uploadOneFile(bucket_url, params, filepath):\n",
    "\n",
    "    # Give file\n",
    "    p = Path(filepath)\n",
    "    file = p.open(\"rb\")\n",
    "    filename = p.name\n",
    "    \n",
    "    # Upload file\n",
    "    r = requests.put(\"%s/%s\" % (bucket_url, filename), data=file, params=params)\n",
    "    \n",
    "    return r.json()\n",
    "    \n",
    "def uploadDirectory(bucket_url, params, dirpath):\n",
    "\n",
    "    # Find all files in directory\n",
    "    \n",
    "    p = Path(dirpath)\n",
    "    allfil = list(p.glob('*'))\n",
    "    allfiles = [i.open(\"rb\") for i in allfil]\n",
    "    allfilenames = [i.name for i in allfil]\n",
    "    \n",
    "    # Upload files\n",
    "    rs = []\n",
    "    for i in range(len(allfiles)):\n",
    "        r = requests.put(\"%s/%s\" % (bucket_url, allfilenames[i]), data=allfiles[i], params=params)\n",
    "        rs.append(r.json())\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## publprofil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/publprofil.yaml') as yml:\n",
    "    pp = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "pp = pp['ResearchObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pck, pmk, pprk, prk, pak = findkeys(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./data/Parapegmata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfile = list(p.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfn = set([i.name for i in allfile if not i.suffix == '.cite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(sorted([i for i in allfile if str(i).split('.')[-1] == 'cite']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = openfile(c)['ResearchObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cck, cmk, cprk, crk, cak = findkeys(cite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caks = [set(i) for i in cak]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = set([i['File'.lower()] for i in cite['Resources']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(sorted([i for i in allfile if not i.suffix == '.cite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDFkeys = [set(openfile(f).keys()) for f in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Metadata keys & Attributes are not empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All metadata keys and attributes are filled, wonderful!\n"
     ]
    }
   ],
   "source": [
    "cmke, cake, message1 = checkVal(cite, pmk, pak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check existence of all keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n",
      "The key File does not exist in your metadata, please add it!\n"
     ]
    }
   ],
   "source": [
    "c1 = checkkeys(pck, cck)\n",
    "c2 = checkkeys(pmk, cmk)\n",
    "c3 = []\n",
    "for i in cprk:\n",
    "    c3.append(checkkeys(prk, i))\n",
    "message2 = congrat(c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If data is identical to cite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milet.json\n",
      "0\n",
      "You did not commented the key {'addition_ID', 'zodiac_part_ID', 'feast_ID', 'feast', 'ID', 'text_string', 'feast_greek', 'addition', 'addition_greek', 'zodiac_part'} in your cite! Please to so!\n",
      "The key {'parallel', 'meteo_event_class_ID', 'parallel_ID', 'authority', 'meteo_event_class', 'record_ID', 'authority_ID'} is not your data, please remove it from the cite!\n",
      "Madrid.json\n",
      "1\n",
      "Paris.json\n",
      "2\n",
      "You did not commented the key {'day_length_fractions', 'month', 'length_month', 'meteo_addition_text_string', 'night_length_fractions', 'zodiac_part', 'meteo_statement', 'day_length', 'night_length_greek', 'day', 'column', 'addition_text_string_greek', 'season', 'zodiac_part_ID', 'season_greek', 'day_length_greek', 'fragment', 'night_length_footnote', 'addition_text_string', 'text_passage', 'night_length', 'day_length_footnote', 'month_ID', 'meteo_addition_text_string_greek', 'season_ID'} in your cite! Please to so!\n",
      "The key {'authority_ID_Meteo', 'meteo_event_class_ID', 'authority_Meteo', 'hole_type_ID', 'hole_No', 'meteo_event_class', 'fragment_ID', 'hole_type', 'authority_ID_Astro', 'authority_Astro'} is not your data, please remove it from the cite!\n",
      "Geminos.json\n",
      "3\n",
      "You did not commented the key {'supplement_Meteo', 'supplement_ID'} in your cite! Please to so!\n",
      "The key {'addition_ID', 'zodiac_part_ID', 'feast_ID', 'feast', 'feast_greek', 'addition', 'addition_greek', 'zodiac_part'} is not your data, please remove it from the cite!\n",
      "Oxford.json\n",
      "4\n",
      "You did not commented the key {'authority_ID_Meteo', 'meteo_event_class_ID', 'authority_Meteo', 'hole_type_ID', 'hole_No', 'meteo_event_class', 'fragment_ID', 'hole_type', 'authority_ID_Astro', 'authority_Astro'} in your cite! Please to so!\n",
      "The key {'day_length_fractions', 'month', 'length_month', 'meteo_addition_text_string', 'night_length_fractions', 'zodiac_part', 'meteo_statement', 'day_length', 'night_length_greek', 'day', 'column', 'addition_text_string_greek', 'season', 'zodiac_part_ID', 'season_greek', 'day_length_greek', 'fragment', 'type', 'night_length_footnote', 'addition_text_string', 'night_length', 'text_passage', 'day_length_footnote', 'month_ID', 'meteo_addition_text_string_greek', 'season_ID'} is not your data, please remove it from the cite!\n",
      "Hibeh.json\n",
      "5\n",
      "You did not commented the key {'feast_ID', 'feast', 'meteo_event_class_ID', 'meteo_event_class', 'feast_greek'} in your cite! Please to so!\n",
      "The key {'text_string', 'supplement_Meteo', 'supplement_ID'} is not your data, please remove it from the cite!\n",
      "Antiochos.json\n",
      "6\n",
      "You did not commented the key {'addition_ID', 'status', 'supplement_ID', 'Authority_ID', 'authority', 'addition', 'addition_greek'} in your cite! Please to so!\n",
      "The key {'feast_ID', 'feast', 'feast_greek'} is not your data, please remove it from the cite!\n",
      "Phaseis.json\n",
      "7\n",
      "You did not commented the key {'parallel_ID', 'parallel', 'authority_ID', 'record_ID'} in your cite! Please to so!\n",
      "The key {'addition_ID', 'status', 'ID', 'supplement_ID', 'Authority_ID', 'addition', 'addition_greek'} is not your data, please remove it from the cite!\n"
     ]
    }
   ],
   "source": [
    "missf, addedf, missk, addedk, message3 = comparekeys(allfn, cf, caks, dataDFkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload on Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is any error in the cite, the process is terminated; otherwise one proceed with upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if (message1 or message2 or message3):\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sandbox (for testing purposes) = sandbox ACCESS_TOKEN from https://sandbox.zenodo.org/account/settings/applications/tokens/new/\n",
    "\n",
    "real data (for real upload) = ACCESS_TOKEN from https://zenodo.org/account/settings/applications/tokens/new/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Register for a Zenodo sandbox account if you don't already have one.\n",
    "    Go to https://sandbox.zenodo.org/account/settings/applications/tokens/new/.\n",
    "    Select the OAuth scopes you need (for the quick start tutorial you need deposit:write and deposit:actions).\n",
    "    Please insert your just generated token for ... below.\n",
    "'''\n",
    "\n",
    "ACCESS_TOKEN = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLY CHANGE SANDBOX TO FALSE IF YOU KNOW WHAT YOU ARE DOING, THIS WILL BE A REAL UPLOAD THEN! If you want to test something always use sandbox!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "bucket_url, params = makeEmptyUpload(True, ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a number lower than 400 everything is fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:10.461734+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Antiochos.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Antiochos.json?versionId=fb16f68e-5b7a-4a53-912e-f4480ecb44d1',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Antiochos.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:10.455055+00:00',\n",
       "  'checksum': 'md5:9f8b8b88c310dc7256f23ae114eecb10',\n",
       "  'version_id': 'fb16f68e-5b7a-4a53-912e-f4480ecb44d1',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Antiochos.json',\n",
       "  'size': 78439},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:10.998593+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Geminos.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Geminos.json?versionId=5e82321a-aa1b-4ecb-b1a9-eaa7d1fc26ee',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Geminos.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:10.993280+00:00',\n",
       "  'checksum': 'md5:84278864159cdef63ed7f6e4dca997a5',\n",
       "  'version_id': '5e82321a-aa1b-4ecb-b1a9-eaa7d1fc26ee',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Geminos.json',\n",
       "  'size': 303197},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:11.297076+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Hibeh.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Hibeh.json?versionId=0169900c-86ef-4d53-a9ec-77764f10ce39',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Hibeh.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:11.291805+00:00',\n",
       "  'checksum': 'md5:8e0d25ec5398bf288250ed6892ba6615',\n",
       "  'version_id': '0169900c-86ef-4d53-a9ec-77764f10ce39',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Hibeh.json',\n",
       "  'size': 46200},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:11.642247+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Madrid.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Madrid.json?versionId=5524dfd6-1ad1-479a-99aa-4dc5a923bc3b',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Madrid.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:11.634381+00:00',\n",
       "  'checksum': 'md5:7c700e14d8d04d0041db949db451fb9b',\n",
       "  'version_id': '5524dfd6-1ad1-479a-99aa-4dc5a923bc3b',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Madrid.json',\n",
       "  'size': 83574},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:12.116721+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Milet.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Milet.json?versionId=82f9cc11-ebee-42bf-94a5-afa42d74f5c3',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Milet.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:12.111106+00:00',\n",
       "  'checksum': 'md5:b1ecb72148b8a5c3e878f3d074b8ad97',\n",
       "  'version_id': '82f9cc11-ebee-42bf-94a5-afa42d74f5c3',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Milet.json',\n",
       "  'size': 28419},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:12.404082+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Oxford.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Oxford.json?versionId=669dd8e1-4a27-463a-9139-debd9e4119c7',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Oxford.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:12.399069+00:00',\n",
       "  'checksum': 'md5:e69ecabd1b3049fa858178cd0a4bfe67',\n",
       "  'version_id': '669dd8e1-4a27-463a-9139-debd9e4119c7',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Oxford.json',\n",
       "  'size': 33330},\n",
       " {'mimetype': 'application/octet-stream',\n",
       "  'updated': '2020-12-16T10:46:12.656568+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Parapegmata.cite',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Parapegmata.cite?versionId=cbe6751a-22fd-4692-824f-885ebe4a0f0d',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Parapegmata.cite?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:12.651910+00:00',\n",
       "  'checksum': 'md5:ffe53c1cefcede6529615ca3ca6d7db9',\n",
       "  'version_id': 'cbe6751a-22fd-4692-824f-885ebe4a0f0d',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Parapegmata.cite',\n",
       "  'size': 16270},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:12.966468+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Paris.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Paris.json?versionId=c27c8048-fa80-4674-a774-67812622a67d',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Paris.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:12.960431+00:00',\n",
       "  'checksum': 'md5:6917abbae53d2669ea1e773cf272c0a4',\n",
       "  'version_id': 'c27c8048-fa80-4674-a774-67812622a67d',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Paris.json',\n",
       "  'size': 127034},\n",
       " {'mimetype': 'application/json',\n",
       "  'updated': '2020-12-16T10:46:13.290260+00:00',\n",
       "  'links': {'self': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Phaseis.json',\n",
       "   'version': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Phaseis.json?versionId=45727d9b-dfe8-4e2d-9220-f6571d45a4ad',\n",
       "   'uploads': 'https://sandbox.zenodo.org/api/files/8530cff0-7b19-4a56-a862-c047e5b32eed/Phaseis.json?uploads'},\n",
       "  'is_head': True,\n",
       "  'created': '2020-12-16T10:46:13.284010+00:00',\n",
       "  'checksum': 'md5:33deed0fdb34e2ff81a5904430c7d1b1',\n",
       "  'version_id': '45727d9b-dfe8-4e2d-9220-f6571d45a4ad',\n",
       "  'delete_marker': False,\n",
       "  'key': 'Phaseis.json',\n",
       "  'size': 920426}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadDirectory(bucket_url, params, str(p.resolve()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
